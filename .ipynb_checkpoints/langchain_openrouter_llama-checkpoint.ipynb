{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf1c1f3",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "**Oftentimes, we want to test some LLMs that are not widely available or are expensive to host. There are various ways to still get your hands dirty with them.**\n",
    "\n",
    "\n",
    "**In this notebook, I'm showing how to use LangChain's CustomLLM together with <a href=\"https://openrouter.ai/\">OpenRouter.ai</a>'s collection of LLMs (like gpt-4-32k, claude-2, and many more) to use these models in your LangChain apps.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06380a21",
   "metadata": {},
   "source": [
    "### <font color='gray'>Loading libraries and variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "547144cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e8ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b351134a-3d15-46e2-bf56-72fa649f0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "MODEL = \"phind/phind-codellama-34b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a7851",
   "metadata": {},
   "source": [
    "# Setting up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0958ec7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(openai_api_key\u001b[38;5;241m=\u001b[39mAPI_KEY, openai_api_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://openrouter.ai/api/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[43mMODEL\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODEL' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, openai_api_base=\"https://openrouter.ai/api/v1\", model_name=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c78ad91",
   "metadata": {},
   "source": [
    "# Let's test our brand new custom LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b366016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here is a python script that calculates the first n Fibonacci numbers using dynamic programming caching:\\n\\n```python\\nimport sys\\n\\ndef fibonacci(n, cache):\\n    if n in cache:\\n        return cache[n]\\n    \\n    if n == 0:\\n        return 0\\n    elif n == 1:\\n        return 1\\n    else:\\n        result = fibonacci(n-1, cache) + fibonacci(n-2, cache)\\n        cache[n] = result\\n        return result\\n\\nif __name__ == \"__main__\":\\n    if len(sys.argv) != 2:\\n        print(\"Usage: python fibonacci.py <n>\")\\n        sys.exit(1)\\n    \\n    n = int(sys.argv[1])\\n    cache = {}\\n    fibonacci_sequence = [fibonacci(i, cache) for i in range(n)]\\n    \\n    print(\"The first\", n, \"Fibonacci numbers are:\")\\n    print(fibonacci_sequence)\\n```\\n\\nYou can run this script by providing the value of n as a command line argument. For example, if you want to calculate the first 10 Fibonacci numbers, you can run the script like this:\\n\\n```bash\\npython fibonacci.py 10\\n```\\n\\nThis will output the first 10 Fibonacci numbers calculated using dynamic programming caching.', response_metadata={'token_usage': {'completion_tokens': 254, 'prompt_tokens': 29, 'total_tokens': 283, 'total_cost': 0.0003955}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b643cd3e-8271-4951-8905-d9869455c70f-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Create a python script to calculate the first n (provided as command line argument) fibonacci numbers with dynamic programming caching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4d6390d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello, I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't actually have personal traits, goals or an identity. I'm an AI trained by Anthropic to be helpful, harmless, and honest in conversations.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
